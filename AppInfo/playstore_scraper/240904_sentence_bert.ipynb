{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jeleez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일에서 데이터 불러오기\n",
    "apps_data = pd.read_csv('cleaned_apps_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 앱 이름을 불용어 리스트로 처리\n",
    "app_names = apps_data['Name'].apply(lambda x: x.lower()).tolist()  # 앱 이름을 소문자로 변환하여 리스트로 수집\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 추가적인 불용어 정의\n",
    "additional_stopwords = ['pdf', 'file', 'app', 'lite', 'application']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 기본 불용어와 추가 불용어 결합\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS.union(app_names).union(additional_stopwords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeleez\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2. Sentence-BERT 모델 로드 및 문장 임베딩 생성\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Sentence-BERT 모델\n",
    "embeddings = model.encode(apps_data['Cleaned_Description'].values)  # 앱 설명에 대한 임베딩 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeleez\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# 3. K-Means 클러스터링 수행\n",
    "n_clusters = 5  # 클러스터 수 설정\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 클러스터 결과를 데이터프레임에 추가\n",
    "apps_data['Cluster'] = clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeleez\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['05', '09', '10', '10in1', '125', '152', '153', '164', '2024', '2025', '252', '264', '309', '4x', '51', '7000', 'acro', 'adblocker', 'ads', 'agoda', 'ai', 'air', 'airplay', 'airreceiver', 'aliexpress', 'alpinequest', 'analog', 'anatomy', 'ancient', 'annotations', 'apparel', 'arar', 'assen', 'astro', 'atlas', 'audio', 'band', 'bethlehem', 'bible', 'bike', 'billionaire', 'blocker', 'book', 'booster', 'boy', 'breitling', 'bs', 'buy', 'camera', 'capcut', 'car', 'carrera', 'cast', 'celest1710', 'chak', 'cheap', 'cherieviewer', 'classic', 'clock', 'codec', 'com', 'comic', 'comicviewer', 'counter', 'coupang', 'creator', 'd036', 'd182', 'ddmusic', 'delivery', 'delta', 'dict', 'digi', 'digital', 'disney', 'divx', 'dlna', 'document', 'documents', 'docx', 'dosbox', 'drama', 'dramabox', 'dramas', 'driver', 'duolingo', 'eats', 'edition', 'editor', 'elegant', 'emulator', 'english', 'epub', 'everyday', 'explorer', 'face', 'fallout', 'fas', 'faster', 'filmhwa', 'filter', 'finder', 'fix', 'fl', 'flashlight', 'flights', 'flud', 'food', 'frost', 'fs', 'fw100', 'galaxy', 'gallery', 'game', 'gemini', 'gfx', 'gold', 'google', 'gp', 'groups', 'gs25', 'gs더프레시', 'hands', 'headunit', 'heic', 'heuer', 'hmk', 'hmkwatch', 'hotels', 'human', 'hur', 'hwa', 'hybrid', 'ibis', 'illuminator', 'ireal', 'jcd', 'jw198', 'jw200', 'jw214', 'jwstudio', 'kakao', 'kakaomap', 'kakaotalk', 'karrot', 'kb', 'kb스타뱅킹', 'kmplayer', 'korean', 'kream', 'lag', 'language', 'launcher', 'led', 'lessons', 'lg', 'lifeplus', 'light', 'like', 'locally', 'location', 'magic', 'manager', 'map', 'mapping', 'md242', 'md301', 'md307', 'md324', 'md335', 'md338', 'messenger', 'metronome', 'military', 'mimix', 'min', 'mind', 'minimal', 'mobile', 'money', 'moneywalk', 'monimo', 'mp3', 'music', 'mx03', 'naver', 'navigation', 'nfc', 'nh', 'nh콕뱅크', 'nh페이', 'nike', 'notes', 'noteshelf', 'obd', 'office', 'oruxmaps', 'os', 'paint', 'papago', 'paper', 'pay', 'pip', 'pixel', 'plague', 'play', 'player', 'plus', 'podcasts', 'poweramp', 'prado', 'prime', 'pro', 'psplay', 'rally', 'ranger', 'reader', 'reloaded', 'remote', 'remove', 'retro', 'rewards', 'road', 's4u', 'samsung', 'samwatch', 'scanner', 'scenario', 'se', 'sell', 'share', 'sharper', 'sheet', 'shoes', 'shop', 'shopping', 'shops', 'shortmax', 'shorts', 'signature', 'silver', 'simple', 'simplemind', 'sirius', 'smart', 'sol뱅크', 'sol페이', 'space', 'space1', 'spotify', 'step', 'stories', 'stream', 'studio', 'style', 'superocean', 'switch', 't50', 'tactical', 'tag', 'taxi', 'tempo', 'temu', 'textreader', 'thinq', 'time', 'tools', 'torch', 'torque', 'torrent', 'translator', 'tribes', 'trip', 'ultra', 'unicorn', 'unlocker', 'usb', 'v3', 'version', 'video', 'viewer', 'vip', 'voron', 'w263', 'watch', 'watchface', 'wfp', 'wonder', 'word', 'zigzag', 'zulu', 'µtorrent', '가격', '가득한', '간편하게', '개인비서', '건강보험증', '결제', '경기도', '곁에', '고속버스', '공항버스', '구할', '국가보훈등록증', '국민가게', '국민연금', '국세청', '굴삭기', '궁합', '급구', '기회소득', '기후동행카드를', '기후행동', '나만의', '내차시세', '내차팔기', '네이버', '농사', '농협', '능력', '다이소몰', '대리운전', '대중교통', '대표플랫폼', '도구', '도사폰', '돈기운', '돈이', '되는', '디지로카', '따릉이', '라이프플러스', '렌터카', '롯데카드', '뤼튼', '만보기', '만세력', '면허시험', '모니모', '모바일', '모바일로', '모바일신분증', '모바일티머니', '무신사', '무제한', '뱅킹', '번호판', '베들레헴', '변동', '보이스피싱', '브랜드', '비플페이', '사주', '삼성금융네트웍스', '성경', '세계', '손택스', '쇼핑', '스마트', '스마트폰', '스미싱', '스토어', '시뮬레이터', '시외버스', '시티즌코난', '신분증', '신한', '신한은행', '신한카드', '실시간', '알림', '알바', '앱테크', '야핏무브', '에이닷', '역학', '오늘도', '옥철이_디저트타임', '온누리페이', '온라인', '와인25플러스', '우리won뱅킹', '우리동네gs', '우리은행', '운동습관', '운세', '운전면허증', '움직이면', '위택스', '은행', '이기상', '이름', '이지포스', '재외국민증', '적립형', '주차', '지리다', '지역사랑상품권', '지역상품권', '지피지기', '첫화면', '최저가', '카톡테마', '캐시워크', '쿠팡', '쿠폰', '크림', '킥보드', '택시', '토정비결', '통신도', '트라이브', '티맵', '티머니go', '팟스타', '패션', '포스티', '폴리스', '폴센트', '피싱아이즈', '필수앱', '하나원큐는', '하나은행', '하루', '한국사', '핫딜', '해몽', '헤이딜러', '홈택스'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 7. TF-IDF 기반 주요 키워드 추출 함수\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words, max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(apps_data['Cleaned_Description'])\n",
    "\n",
    "def get_top_keywords(tfidf_matrix, clusters, top_n=5):\n",
    "    cluster_centers = np.zeros((np.unique(clusters).size, tfidf_matrix.shape[1]))\n",
    "    \n",
    "    for cluster in np.unique(clusters):\n",
    "        cluster_centers[cluster] = tfidf_matrix[clusters == cluster].mean(axis=0)\n",
    "    \n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    top_keywords = []\n",
    "    \n",
    "    for cluster in range(cluster_centers.shape[0]):\n",
    "        center = cluster_centers[cluster]\n",
    "        top_indices = center.argsort()[::-1][:top_n]\n",
    "        keywords = [terms[i] for i in top_indices]\n",
    "        top_keywords.append(keywords)\n",
    "    \n",
    "    return top_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 클러스터별 상위 5개 키워드 추출\n",
    "top_keywords_per_cluster = get_top_keywords(tfidf_matrix, clusters, top_n=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 키워드 기반으로 상위 카테고리 이름 생성\n",
    "def generate_category_name(keywords):\n",
    "    return \" & \".join(keywords[:2])  # 상위 2개의 키워드를 연결하여 이름 생성\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. WordNet을 사용하여 키워드를 일반화하는 함수\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_word(word):\n",
    "    synsets = wordnet.synsets(word)\n",
    "    if synsets:\n",
    "        # 첫 번째 동의어 집합을 사용하여 일반화\n",
    "        hypernyms = synsets[0].hypernyms()\n",
    "        if hypernyms:\n",
    "            return hypernyms[0].lemmas()[0].name()  # 가장 일반적인 상위 단어 반환\n",
    "    return word  # 동의어 집합이 없으면 원래 단어 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 키워드 기반으로 상위 카테고리 이름 생성\n",
    "def generate_category_name(keywords):\n",
    "    generalized_keywords = [generalize_word(kw) for kw in keywords]\n",
    "    return \" & \".join(generalized_keywords[:2])  # 상위 2개의 일반화된 키워드를 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 Name: timepiece & external_body_part\n",
      "Cluster 1 Name: paper & mobile\n",
      "Cluster 2 Name: commodity & property\n",
      "Cluster 3 Name: record & scholar\n",
      "Cluster 4 Name: auditory_communication & visual_communication\n"
     ]
    }
   ],
   "source": [
    "# 11. 클러스터별 상위 카테고리 이름 생성 및 출력\n",
    "for cluster_num, keywords in enumerate(top_keywords_per_cluster):\n",
    "    category_name = generate_category_name(keywords)\n",
    "    print(f\"Cluster {cluster_num} Name: {category_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. 클러스터 이름을 데이터프레임에 추가\n",
    "for cluster_num, keywords in enumerate(top_keywords_per_cluster):\n",
    "    category_name = generate_category_name(keywords)\n",
    "    apps_data.loc[apps_data['Cluster'] == cluster_num, 'Super_Category'] = category_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Name          Category  \\\n",
      "0                 PDF Reader             Tools   \n",
      "1                  모바일 건강보험증  Health & Fitness   \n",
      "2       All Documents Viewer      Productivity   \n",
      "3      A.(에이닷) - 나만의 AI 개인비서         Lifestyle   \n",
      "4                     온누리상품권           Finance   \n",
      "..                       ...               ...   \n",
      "190              OruxMaps GP    Travel & Local   \n",
      "191           굴삭기 면허시험 시뮬레이터         Education   \n",
      "192  EVERYDAY 10-Hands Style   Personalization   \n",
      "193               Astro Gold         Lifestyle   \n",
      "194  ACRO Classic Wonder T50   Personalization   \n",
      "\n",
      "                                   Cleaned_Description  Cluster  \\\n",
      "0    PDF app Android best viewer viewing PDF PDF Re...        3   \n",
      "1    1 mobile health insurance card app public serv...        1   \n",
      "2    features include View Multiple Types Files Sca...        3   \n",
      "3    Adot newly evolved AI personal assistant AI pe...        4   \n",
      "4    Onnuri Gift Certificate service allows conveni...        1   \n",
      "..                                                 ...      ...   \n",
      "190  use OruxMaps outdoor activities Online offline...        2   \n",
      "191  app made practical test excavators practice Li...        4   \n",
      "192  beautiful watch face every day Easy read custo...        0   \n",
      "193  Astro Gold professionallevel astrology Android...        2   \n",
      "194  Introducing watch faces add value change 6 dif...        0   \n",
      "\n",
      "                                    Super_Category  \n",
      "0                                 record & scholar  \n",
      "1                                   paper & mobile  \n",
      "2                                 record & scholar  \n",
      "3    auditory_communication & visual_communication  \n",
      "4                                   paper & mobile  \n",
      "..                                             ...  \n",
      "190                           commodity & property  \n",
      "191  auditory_communication & visual_communication  \n",
      "192                 timepiece & external_body_part  \n",
      "193                           commodity & property  \n",
      "194                 timepiece & external_body_part  \n",
      "\n",
      "[195 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 10. 결과 확인\n",
    "print(apps_data[['Name', 'Category', 'Cleaned_Description', 'Cluster', 'Super_Category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering 'clustered_apps_data.csv' 파일로 저장\n",
    "apps_data.to_csv('clustered_apps_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering 'clustered_apps_data.csv' 파일로 저장\n",
    "apps_data.to_excel('clustered_apps_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. WordNet을 사용하여 키워드의 상위 개념을 찾는 함수\n",
    "def get_hypernyms(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    if synsets:\n",
    "        hypernyms = synsets[0].hypernyms()\n",
    "        if hypernyms:\n",
    "            return hypernyms[0].lemmas()[0].name()  # 첫 번째 상위 개념 반환\n",
    "    return word  # 상위 개념이 없으면 원래 단어 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 키워드를 상위 개념으로 변환하는 함수\n",
    "def generalize_keywords(keywords):\n",
    "    generalized_keywords = [get_hypernyms(word) for word in keywords]\n",
    "    return generalized_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeleez\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 4. Sentence-BERT 모델 로드 및 문장 임베딩 생성\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(apps_data['Description'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeleez\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# 5. K-Means 클러스터링 수행\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. TF-IDF 기반 주요 키워드 추출\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(apps_data['Cleaned_Description'])\n",
    "\n",
    "def get_top_keywords(tfidf_matrix, clusters, top_n=5):\n",
    "    cluster_centers = np.zeros((np.unique(clusters).size, tfidf_matrix.shape[1]))\n",
    "    \n",
    "    for cluster in np.unique(clusters):\n",
    "        cluster_centers[cluster] = tfidf_matrix[clusters == cluster].mean(axis=0)\n",
    "    \n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    top_keywords = []\n",
    "    \n",
    "    for cluster in range(cluster_centers.shape[0]):\n",
    "        center = cluster_centers[cluster]\n",
    "        top_indices = center.argsort()[::-1][:top_n]\n",
    "        keywords = [terms[i] for i in top_indices]\n",
    "        top_keywords.append(keywords)\n",
    "    \n",
    "    return top_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 클러스터별 상위 5개 키워드 추출\n",
    "top_keywords_per_cluster = get_top_keywords(tfidf_matrix, clusters, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 상위 개념 기반 카테고리 이름 생성\n",
    "def generate_category_name(keywords):\n",
    "    generalized_keywords = generalize_keywords(keywords)\n",
    "    return \" & \".join(set(generalized_keywords[:2]))  # 중복되지 않은 상위 2개의 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 Name: app & representation\n",
      "Cluster 1 Name: pdf & record\n",
      "Cluster 2 Name: timepiece & external_body_part\n",
      "Cluster 3 Name: visual_communication & auditory_communication\n",
      "Cluster 4 Name: mobile & paper\n"
     ]
    }
   ],
   "source": [
    "# 10. 클러스터별 상위 카테고리 이름 생성 및 출력\n",
    "for cluster_num, keywords in enumerate(top_keywords_per_cluster):\n",
    "    category_name = generate_category_name(keywords)\n",
    "    print(f\"Cluster {cluster_num} Name: {category_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. TF-IDF 기반 주요 키워드 추출\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(apps_data['Cleaned_Description'])\n",
    "\n",
    "def get_top_keywords(tfidf_matrix, clusters, top_n=5):\n",
    "    cluster_centers = np.zeros((np.unique(clusters).size, tfidf_matrix.shape[1]))\n",
    "    \n",
    "    for cluster in np.unique(clusters):\n",
    "        cluster_centers[cluster] = tfidf_matrix[clusters == cluster].mean(axis=0)\n",
    "    \n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    top_keywords = []\n",
    "    \n",
    "    for cluster in range(cluster_centers.shape[0]):\n",
    "        center = cluster_centers[cluster]\n",
    "        top_indices = center.argsort()[::-1][:top_n]\n",
    "        keywords = [terms[i] for i in top_indices]\n",
    "        top_keywords.append(keywords)\n",
    "    \n",
    "    return top_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 클러스터별 상위 5개 키워드 추출\n",
    "top_keywords_per_cluster = get_top_keywords(tfidf_matrix, clusters, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 각 키워드를 임베딩하여 벡터 생성\n",
    "def get_keyword_embedding(keywords):\n",
    "    return model.encode(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Cosine Similarity를 사용하여 중심 단어 선택\n",
    "def select_representative_word(keywords):\n",
    "    keyword_embeddings = get_keyword_embedding(keywords)\n",
    "    similarity_matrix = cosine_similarity(keyword_embeddings)\n",
    "\n",
    "    # 각 단어의 유사도 합 계산\n",
    "    similarity_sums = similarity_matrix.sum(axis=1)\n",
    "    \n",
    "    # 유사도 합이 가장 큰 단어를 대표 단어로 선택\n",
    "    representative_idx = np.argmax(similarity_sums)\n",
    "    return keywords[representative_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 클러스터별 대표 단어 생성\n",
    "def generate_category_name(keywords):\n",
    "    return select_representative_word(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 Name: face\n",
      "Cluster 1 Name: payment\n",
      "Cluster 2 Name: products\n",
      "Cluster 3 Name: reader\n",
      "Cluster 4 Name: videos\n"
     ]
    }
   ],
   "source": [
    "# 10. 클러스터별 대표 단어 생성 및 출력\n",
    "for cluster_num, keywords in enumerate(top_keywords_per_cluster):\n",
    "    category_name = generate_category_name(keywords)\n",
    "    print(f\"Cluster {cluster_num} Name: {category_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. 클러스터 이름을 데이터프레임에 추가\n",
    "for cluster_num, keywords in enumerate(top_keywords_per_cluster):\n",
    "    category_name = generate_category_name(keywords)\n",
    "    apps_data.loc[apps_data['Cluster'] == cluster_num, 'Super_Category'] = category_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Name          Category  \\\n",
      "0                 PDF Reader             Tools   \n",
      "1                  모바일 건강보험증  Health & Fitness   \n",
      "2       All Documents Viewer      Productivity   \n",
      "3      A.(에이닷) - 나만의 AI 개인비서         Lifestyle   \n",
      "4                     온누리상품권           Finance   \n",
      "..                       ...               ...   \n",
      "190              OruxMaps GP    Travel & Local   \n",
      "191           굴삭기 면허시험 시뮬레이터         Education   \n",
      "192  EVERYDAY 10-Hands Style   Personalization   \n",
      "193               Astro Gold         Lifestyle   \n",
      "194  ACRO Classic Wonder T50   Personalization   \n",
      "\n",
      "                                           Description  Cluster Super_Category  \n",
      "0    This is a PDF app for Android and the best vie...        3         reader  \n",
      "1    1. The mobile health insurance card app is a p...        1        payment  \n",
      "2    Our features include: View Multiple Types of F...        3         reader  \n",
      "3    Adot, your own newly evolved AI personal assis...        4         videos  \n",
      "4    Onnuri Gift Certificate is a service that allo...        1        payment  \n",
      "..                                                 ...      ...            ...  \n",
      "190  You can use OruxMaps for your outdoor activiti...        2       products  \n",
      "191  The app made for the practical test excavators...        4         videos  \n",
      "192  A beautiful watch face for every day! Easy to ...        0           face  \n",
      "193  Astro Gold is the professional-level astrology...        2       products  \n",
      "194  Introducing watch faces that add value to you....        0           face  \n",
      "\n",
      "[195 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인\n",
    "print(apps_data[['Name', 'Category', 'Description', 'Cluster', 'Super_Category']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
