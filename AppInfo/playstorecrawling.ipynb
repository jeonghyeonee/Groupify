{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\jeleez\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jeleez\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.12.3)\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.22.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jeleez\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jeleez\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jeleez\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jeleez\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jeleez\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.25.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\jeleez\\appdata\\roaming\\python\\python38\\site-packages (from selenium) (4.11.0)\n",
      "Collecting websocket-client>=1.8.0 (from selenium)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\jeleez\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=1.14 (from trio~=0.17->selenium)\n",
      "  Downloading cffi-1.16.0-cp38-cp38-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting exceptiongroup (from trio~=0.17->selenium)\n",
      "  Downloading exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->trio~=0.17->selenium)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.22.0-py3-none-any.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/9.4 MB 2.4 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/9.4 MB 2.9 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/9.4 MB 4.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.5/9.4 MB 7.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.6/9.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.0/9.4 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.6/9.4 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.8/9.4 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.2/9.4 MB 12.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.4/9.4 MB 13.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.6/9.4 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.4 MB 16.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 15.9 MB/s eta 0:00:00\n",
      "Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
      "   ---------------------------------------- 0.0/467.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 467.7/467.7 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading cffi-1.16.0-cp38-cp38-win_amd64.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 181.4/181.4 kB ? eta 0:00:00\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: sortedcontainers, websocket-client, sniffio, pysocks, pycparser, outcome, h11, exceptiongroup, wsproto, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed cffi-1.16.0 exceptiongroup-1.2.1 h11-0.14.0 outcome-1.3.0.post0 pycparser-2.22 pysocks-1.7.1 selenium-4.22.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.25.1 trio-websocket-0.11.1 websocket-client-1.8.0 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 플레이스토어 URL\n",
    "url = \"https://play.google.com/store/apps/details?id=com.kakao.talk\"\n",
    "\n",
    "# HTTP GET 요청\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App Title: KakaoTalk : Messenger\n",
      "App Description: KakaoTalk - fast, fun, and reliable messenger for all\n",
      "App Category: #1 popular communication\n"
     ]
    }
   ],
   "source": [
    "# 요청이 성공했는지 확인\n",
    "if response.status_code == 200:\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # 앱 제목 가져오기\n",
    "    app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "    print(f\"App Title: {app_title}\")\n",
    "\n",
    "    # 앱 설명 가져오기\n",
    "    app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "    app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "    print(f\"App Description: {app_description}\")\n",
    "\n",
    "    # 앱 카테고리 가져오기\n",
    "    app_category_button = soup.find('button', {'data-idom-class': 'Rj2Mlf OLiIxf PDpWxe P62QJc LQeN7 LMoCf'})\n",
    "    app_category = app_category_button.find('span', {'jsname': 'V67aGc'}).text if app_category_button else 'Category not found'\n",
    "    print(f\"App Category: {app_category}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'KakaoTalk : Messenger', 'description': 'KakaoTalk - fast, fun, and reliable messenger for all', 'category': '#1 popular communication'}\n",
      "{'title': 'Naver Papago - AI Translator', 'description': 'Smart AI Translator, dreaming of a world communicating without language barriers', 'category': '#2 popular tools'}\n",
      "{'title': '카카오내비 - 주차,발렛,전기차충전,세차,보험,중고차', 'description': 'The new evolution of navigation, KakaoNavi', 'category': '#7 popular maps & navigation'}\n",
      "{'title': 'NAVER Map, Navigation', 'description': \"South Korea's GPS navigation Get started right away\", 'category': '#2 popular maps & navigation'}\n",
      "{'title': 'Coupang Play', 'description': \"Enjoy COUPANG PLAY's Unlimited Movies&TV shows only for Coupang WOW members.\", 'category': '#2 popular entertainment'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_app_urls(search_query, num_results=1):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        app_urls = []\n",
    "        for a in soup.find_all('a', {'class': 'Si6A0c Gy4nib'}, limit=num_results):\n",
    "            app_url = 'https://play.google.com' + a['href']\n",
    "            app_urls.append(app_url)\n",
    "        \n",
    "        return app_urls\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 앱 제목 가져오기\n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        # 앱 설명 가져오기\n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        # 앱 카테고리 가져오기\n",
    "        app_category_button = soup.find('button', {'data-idom-class': 'Rj2Mlf OLiIxf PDpWxe P62QJc LQeN7 LMoCf'})\n",
    "        app_category = app_category_button.find('span', {'jsname': 'V67aGc'}).text if app_category_button else 'Category not found'\n",
    "        # print(f\"App Category: {app_category}\")\n",
    "        \n",
    "        return {\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "# 앱 이름 리스트\n",
    "app_names = [\"카카오톡\", \"파파고\", \"카카오맵\", \"네이버\", \"쿠팡\"]\n",
    "\n",
    "# 각 앱의 URL 수집 및 정보 크롤링\n",
    "for app_name in app_names:\n",
    "    app_urls = get_app_urls(app_name)\n",
    "    if app_urls:\n",
    "        app_info = get_app_info(app_urls[0])\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://play.google.com/store/apps/details?id=com.kakao.talk', 'title': 'KakaoTalk : Messenger', 'description': 'KakaoTalk - fast, fun, and reliable messenger for all', 'category': 'Category not found'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.naver.labs.translator', 'title': 'Naver Papago - AI Translator', 'description': 'Smart AI Translator, dreaming of a world communicating without language barriers', 'category': 'Category not found'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.locnall.KimGiSa', 'title': '카카오내비 - 주차,발렛,전기차충전,세차,보험,중고차', 'description': 'The new evolution of navigation, KakaoNavi', 'category': 'Category not found'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.nhn.android.nmap', 'title': 'NAVER Map, Navigation', 'description': \"South Korea's GPS navigation Get started right away\", 'category': 'Category not found'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.coupang.mobile.play', 'title': 'Coupang Play', 'description': \"Enjoy COUPANG PLAY's Unlimited Movies&TV shows only for Coupang WOW members.\", 'category': 'Category not found'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_app_urls(search_query, num_results=1):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        app_urls = []\n",
    "        for a in soup.find_all('a', {'class': 'Si6A0c Gy4nib'}, limit=num_results):\n",
    "            app_url = 'https://play.google.com' + a['href']\n",
    "            app_urls.append(app_url)\n",
    "        \n",
    "        return app_urls\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 앱 제목 가져오기\n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        # 앱 설명 가져오기\n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        # 앱 카테고리 가져오기\n",
    "        app_category_button = soup.find('a', {'itemprop': 'genre'})\n",
    "        app_category = app_category_button.text if app_category_button else 'Category not found'\n",
    "        \n",
    "        return {\n",
    "            'url': app_url,\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "# 앱 이름 리스트\n",
    "app_names = [\"카카오톡\", \"파파고\", \"카카오맵\", \"네이버\", \"쿠팡\"]\n",
    "\n",
    "# 각 앱의 URL 수집 및 정보 크롤링\n",
    "for app_name in app_names:\n",
    "    app_urls = get_app_urls(app_name)\n",
    "    if app_urls:\n",
    "        app_info = get_app_info(app_urls[0])\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No URL found for app: 카카오톡\n",
      "No URL found for app: 파파고\n",
      "No URL found for app: 카카오맵\n",
      "No URL found for app: 네이버\n",
      "No URL found for app: 쿠팡\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_app_urls(search_query, expected_name, num_results=5):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        app_urls = []\n",
    "        for a in soup.find_all('a', href=True, limit=num_results):\n",
    "            if '/store/apps/details?id=' in a['href']:\n",
    "                app_url = 'https://play.google.com' + a['href']\n",
    "                app_title_div = a.find('div', {'class': 'WsMG1c nnK0zc'})\n",
    "                if app_title_div:\n",
    "                    app_title = app_title_div.text\n",
    "                    if expected_name.lower() in app_title.lower():\n",
    "                        app_urls.append(app_url)\n",
    "        \n",
    "        return app_urls\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 앱 제목 가져오기\n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        # 앱 설명 가져오기\n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        # 앱 카테고리 가져오기\n",
    "        app_category_button = soup.find('a', {'itemprop': 'genre'})\n",
    "        app_category = app_category_button.text if app_category_button else 'Category not found'\n",
    "        \n",
    "        return {\n",
    "            'url': app_url,\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "# 앱 이름 리스트\n",
    "app_names = {\n",
    "    \"카카오톡\": \"카카오톡 KakaoTalk\",\n",
    "    \"파파고\": \"Papago\",\n",
    "    \"카카오맵\": \"KakaoMap\",\n",
    "    \"네이버\": \"NAVER\",\n",
    "    \"쿠팡\": \"Coupang\"\n",
    "}\n",
    "\n",
    "# 각 앱의 URL 수집 및 정보 크롤링\n",
    "for app_name, expected_name in app_names.items():\n",
    "    app_urls = get_app_urls(app_name, expected_name)\n",
    "    if app_urls:\n",
    "        app_info = get_app_info(app_urls[0])\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No URL found for app: 카카오톡\n",
      "No URL found for app: 파파고\n",
      "No URL found for app: 카카오맵\n",
      "No URL found for app: 네이버\n",
      "No URL found for app: 쿠팡\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_app_urls(search_query, expected_name, num_results=5):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        app_urls = []\n",
    "        for a in soup.find_all('a', href=True, limit=num_results):\n",
    "            if '/store/apps/details?id=' in a['href']:\n",
    "                app_url = 'https://play.google.com' + a['href']\n",
    "                app_title_div = a.find('div', {'class': 'WsMG1c nnK0zc'})\n",
    "                if app_title_div:\n",
    "                    app_title = app_title_div.text\n",
    "                    if expected_name.lower() in app_title.lower():\n",
    "                        app_urls.append(app_url)\n",
    "        \n",
    "        return app_urls\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 앱 제목 가져오기\n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        # 앱 설명 가져오기\n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        # 앱 카테고리 가져오기\n",
    "        app_category_button = soup.find('a', {'itemprop': 'genre'})\n",
    "        app_category = app_category_button.text if app_category_button else 'Category not found'\n",
    "        \n",
    "        return {\n",
    "            'url': app_url,\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "# 앱 이름 리스트\n",
    "app_names = {\n",
    "    \"카카오톡\": \"카카오톡 KakaoTalk\",\n",
    "    \"파파고\": \"Papago\",\n",
    "    \"카카오맵\": \"KakaoMap\",\n",
    "    \"네이버\": \"NAVER\",\n",
    "    \"쿠팡\": \"Coupang\"\n",
    "}\n",
    "\n",
    "# 각 앱의 URL 수집 및 정보 크롤링\n",
    "for app_name, expected_name in app_names.items():\n",
    "    app_urls = get_app_urls(app_name, expected_name)\n",
    "    if app_urls:\n",
    "        app_info = get_app_info(app_urls[0])\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No URL found for app: 카카오톡\n",
      "No URL found for app: 파파고\n",
      "No URL found for app: 카카오맵\n",
      "No URL found for app: 네이버\n",
      "No URL found for app: 쿠팡\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_app_urls(search_query, expected_name, num_results=5):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        app_urls = []\n",
    "        for a in soup.find_all('a', href=True, limit=num_results):\n",
    "            if '/store/apps/details?id=' in a['href']:\n",
    "                app_url = 'https://play.google.com' + a['href']\n",
    "                app_title_div = a.find('span', {'class': 'DdYX5'})\n",
    "                if app_title_div:\n",
    "                    app_title = app_title_div.text\n",
    "                    if expected_name.lower() in app_title.lower():\n",
    "                        app_urls.append(app_url)\n",
    "        \n",
    "        return app_urls\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 앱 제목 가져오기\n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        # 앱 설명 가져오기\n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        # 앱 카테고리 가져오기\n",
    "        app_category_button = soup.find('a', {'itemprop': 'genre'})\n",
    "        app_category = app_category_button.text if app_category_button else 'Category not found'\n",
    "        \n",
    "        return {\n",
    "            'url': app_url,\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "# 앱 이름 리스트\n",
    "app_names = {\n",
    "    \"카카오톡\": \"카카오톡 KakaoTalk\",\n",
    "    \"파파고\": \"Papago\",\n",
    "    \"카카오맵\": \"KakaoMap\",\n",
    "    \"네이버\": \"NAVER\",\n",
    "    \"쿠팡\": \"Coupang\"\n",
    "}\n",
    "\n",
    "# 각 앱의 URL 수집 및 정보 크롤링\n",
    "for app_name, expected_name in app_names.items():\n",
    "    app_urls = get_app_urls(app_name, expected_name)\n",
    "    if app_urls:\n",
    "        app_info = get_app_info(app_urls[0])\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No URL found for app: 카카오톡\n",
      "No URL found for app: 파파고\n",
      "No URL found for app: 카카오맵\n",
      "No URL found for app: 네이버\n",
      "No URL found for app: 쿠팡\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_app_urls(search_query, expected_name, num_results=5):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        app_urls = []\n",
    "        for a in soup.find_all('a', href=True, limit=num_results):\n",
    "            if '/store/apps/details?id=' in a['href']:\n",
    "                app_url = 'https://play.google.com' + a['href']\n",
    "                app_title = a.find('div', {'class': 'WsMG1c nnK0zc'}).text\n",
    "                if expected_name.lower() in app_title.lower():\n",
    "                    app_urls.append(app_url)\n",
    "        \n",
    "        return app_urls\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 앱 제목 가져오기\n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        # 앱 설명 가져오기\n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        # 앱 카테고리 가져오기\n",
    "        app_category_button = soup.find('a', {'itemprop': 'genre'})\n",
    "        app_category = app_category_button.text if app_category_button else 'Category not found'\n",
    "        \n",
    "        return {\n",
    "            'url': app_url,\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "# 앱 이름과 예상된 정확한 제목 매핑 리스트\n",
    "app_names = {\n",
    "    \"카카오톡\": \"카카오톡\",\n",
    "    \"파파고\": \"파파고\",\n",
    "    \"카카오맵\": \"카카오맵\",\n",
    "    \"네이버\": \"네이버\",\n",
    "    \"쿠팡\": \"쿠팡\"\n",
    "}\n",
    "\n",
    "# 각 앱의 URL 수집 및 정보 크롤링\n",
    "for app_name, expected_name in app_names.items():\n",
    "    app_urls = get_app_urls(app_name, expected_name)\n",
    "    if app_urls:\n",
    "        app_info = get_app_info(app_urls[0])\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://play.google.com/store/apps/details?id=com.kakao.talk', 'title': 'KakaoTalk : Messenger', 'description': 'KakaoTalk - fast, fun, and reliable messenger for all', 'category': 'Category not found'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.naver.labs.translator', 'title': 'Naver Papago - AI Translator', 'description': 'Smart AI Translator, dreaming of a world communicating without language barriers', 'category': 'Category not found'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.locnall.KimGiSa', 'title': '카카오내비 - 주차,발렛,전기차충전,세차,보험,중고차', 'description': 'The new evolution of navigation, KakaoNavi', 'category': 'Category not found'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.nhn.android.nmap', 'title': 'NAVER Map, Navigation', 'description': \"South Korea's GPS navigation Get started right away\", 'category': 'Category not found'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.coupang.mobile.play', 'title': 'Coupang Play', 'description': \"Enjoy COUPANG PLAY's Unlimited Movies&TV shows only for Coupang WOW members.\", 'category': 'Category not found'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_first_app_url(search_query):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        first_result = soup.find('a', {'class': 'Si6A0c Gy4nib'})\n",
    "        if first_result:\n",
    "            app_url = 'https://play.google.com' + first_result['href']\n",
    "            return app_url\n",
    "        else:\n",
    "            print(f\"No app found for search query: {search_query}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 앱 제목 가져오기\n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        # 앱 설명 가져오기\n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        # 앱 카테고리 가져오기\n",
    "        app_category_button = soup.find('a', {'itemprop': 'genre'})\n",
    "        app_category = app_category_button.text if app_category_button else 'Category not found'\n",
    "        \n",
    "        return {\n",
    "            'url': app_url,\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# 앱 이름 리스트\n",
    "app_names = [\"카카오톡\", \"파파고\", \"카카오맵\", \"네이버\", \"쿠팡\"]\n",
    "\n",
    "# 각 앱의 URL 수집 및 정보 크롤링\n",
    "for app_name in app_names:\n",
    "    app_url = get_first_app_url(app_name)\n",
    "    if app_url:\n",
    "        app_info = get_app_info(app_url)\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# 각 앱의 URL 수집 및 정보 크롤링\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m app_name, expected_name \u001b[38;5;129;01min\u001b[39;00m app_names\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 83\u001b[0m     app_url \u001b[38;5;241m=\u001b[39m \u001b[43mget_best_match_app_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m app_url:\n\u001b[0;32m     85\u001b[0m         app_info \u001b[38;5;241m=\u001b[39m get_app_info(app_url)\n",
      "Cell \u001b[1;32mIn[16], line 25\u001b[0m, in \u001b[0;36mget_best_match_app_url\u001b[1;34m(search_query, expected_name, num_results)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSi6A0c Gy4nib\u001b[39m\u001b[38;5;124m'\u001b[39m}, limit\u001b[38;5;241m=\u001b[39mnum_results):\n\u001b[0;32m     24\u001b[0m     app_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://play.google.com\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 25\u001b[0m     app_title \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWsMG1c nnK0zc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[0;32m     26\u001b[0m     app_urls\u001b[38;5;241m.\u001b[39mappend(app_url)\n\u001b[0;32m     27\u001b[0m     app_titles\u001b[38;5;241m.\u001b[39mappend(app_title)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_best_match_app_url(search_query, expected_name, num_results=5):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        app_urls = []\n",
    "        app_titles = []\n",
    "        for a in soup.find_all('a', {'class': 'Si6A0c Gy4nib'}, limit=num_results):\n",
    "            app_url = 'https://play.google.com' + a['href']\n",
    "            app_title = a.find('div', {'class': 'WsMG1c nnK0zc'}).text\n",
    "            app_urls.append(app_url)\n",
    "            app_titles.append(app_title)\n",
    "        \n",
    "        # Find the best match\n",
    "        best_match_url = None\n",
    "        for i in range(len(app_titles)):\n",
    "            if expected_name.lower() in app_titles[i].lower():\n",
    "                best_match_url = app_urls[i]\n",
    "                break\n",
    "        \n",
    "        return best_match_url\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 앱 제목 가져오기\n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        # 앱 설명 가져오기\n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        # 앱 카테고리 가져오기\n",
    "        app_category_button = soup.find('a', {'itemprop': 'genre'})\n",
    "        app_category = app_category_button.text if app_category_button else 'Category not found'\n",
    "        \n",
    "        return {\n",
    "            'url': app_url,\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# 앱 이름과 예상된 정확한 제목 매핑 리스트\n",
    "app_names = {\n",
    "    \"카카오톡\": \"KakaoTalk\",\n",
    "    \"파파고\": \"Papago\",\n",
    "    \"카카오맵\": \"KakaoMap\",\n",
    "    \"네이버\": \"NAVER\",\n",
    "    \"쿠팡\": \"Coupang\"\n",
    "}\n",
    "\n",
    "# 각 앱의 URL 수집 및 정보 크롤링\n",
    "for app_name, expected_name in app_names.items():\n",
    "    app_url = get_best_match_app_url(app_name, expected_name)\n",
    "    if app_url:\n",
    "        app_info = get_app_info(app_url)\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://play.google.com/store/apps/details?id=com.kakao.talk', 'title': 'KakaoTalk : Messenger', 'description': 'KakaoTalk - fast, fun, and reliable messenger for all', 'category': '#1 popular communication'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.naver.labs.translator', 'title': 'Naver Papago - AI Translator', 'description': 'Smart AI Translator, dreaming of a world communicating without language barriers', 'category': '#2 popular tools'}\n",
      "No URL found for app: 카카오맵\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.nhn.android.nmap', 'title': 'NAVER Map, Navigation', 'description': \"South Korea's GPS navigation Get started right away\", 'category': '#2 popular maps & navigation'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.coupang.mobile.play', 'title': 'Coupang Play', 'description': \"Enjoy COUPANG PLAY's Unlimited Movies&TV shows only for Coupang WOW members.\", 'category': '#2 popular entertainment'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_best_match_app_url(search_query, expected_name, num_results=5):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        app_urls = []\n",
    "        app_titles = []\n",
    "        for a in soup.find_all('a', {'class': 'Si6A0c Gy4nib'}, limit=num_results):\n",
    "            app_url = 'https://play.google.com' + a['href']\n",
    "            app_title_div = a.find('div', {'class': 'WsMG1c nnK0zc'})\n",
    "            if app_title_div:\n",
    "                app_title = app_title_div.text\n",
    "            else:\n",
    "                app_title_span = a.find('span', {'class': 'DdYX5'})\n",
    "                app_title = app_title_span.text if app_title_span else 'Title not found'\n",
    "            app_urls.append(app_url)\n",
    "            app_titles.append(app_title)\n",
    "        \n",
    "        # Find the best match\n",
    "        best_match_url = None\n",
    "        for i in range(len(app_titles)):\n",
    "            if expected_name.lower() in app_titles[i].lower():\n",
    "                best_match_url = app_urls[i]\n",
    "                break\n",
    "        \n",
    "        return best_match_url\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 앱 제목 가져오기\n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        # 앱 설명 가져오기\n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        # 앱 카테고리 가져오기\n",
    "        app_category_button = soup.find('button', {'data-idom-class': 'Rj2Mlf OLiIxf PDpWxe P62QJc LQeN7 LMoCf'})\n",
    "        app_category = app_category_button.find('span', {'jsname': 'V67aGc'}).text if app_category_button else 'Category not found'\n",
    "        \n",
    "        return {\n",
    "            'url': app_url,\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# 앱 이름과 예상된 정확한 제목 매핑 리스트\n",
    "app_names = {\n",
    "    \"카카오톡\": \"KakaoTalk\",\n",
    "    \"파파고\": \"Papago\",\n",
    "    \"카카오맵\": \"KakaoMap\",\n",
    "    \"네이버\": \"NAVER\",\n",
    "    \"쿠팡\": \"Coupang\"\n",
    "}\n",
    "\n",
    "# 각 앱의 URL 수집 및 정보 크롤링\n",
    "for app_name, expected_name in app_names.items():\n",
    "    app_url = get_best_match_app_url(app_name, expected_name)\n",
    "    if app_url:\n",
    "        app_info = get_app_info(app_url)\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://play.google.com/store/apps/details?id=com.kakao.talk', 'title': 'KakaoTalk : Messenger', 'description': 'KakaoTalk - fast, fun, and reliable messenger for all', 'category': 'Category not found'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.naver.labs.translator', 'title': 'Naver Papago - AI Translator', 'description': 'Smart AI Translator, dreaming of a world communicating without language barriers', 'category': 'Category not found'}\n",
      "No URL found for app: 카카오맵\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.nhn.android.nmap', 'title': 'NAVER Map, Navigation', 'description': \"South Korea's GPS navigation Get started right away\", 'category': 'Category not found'}\n",
      "{'url': 'https://play.google.com/store/apps/details?id=com.coupang.mobile.play', 'title': 'Coupang Play', 'description': \"Enjoy COUPANG PLAY's Unlimited Movies&TV shows only for Coupang WOW members.\", 'category': 'Category not found'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_best_match_app_url(search_query, expected_name, num_results=5):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        app_urls = []\n",
    "        app_titles = []\n",
    "        for a in soup.find_all('a', {'class': 'Si6A0c Gy4nib'}, limit=num_results):\n",
    "            app_url = 'https://play.google.com' + a['href']\n",
    "            app_title_div = a.find('div', {'class': 'WsMG1c nnK0zc'})\n",
    "            if app_title_div:\n",
    "                app_title = app_title_div.text\n",
    "            else:\n",
    "                app_title_span = a.find('span', {'class': 'DdYX5'})\n",
    "                app_title = app_title_span.text if app_title_span else 'Title not found'\n",
    "            app_urls.append(app_url)\n",
    "            app_titles.append(app_title)\n",
    "        \n",
    "        # Find the best match\n",
    "        best_match_url = None\n",
    "        for i in range(len(app_titles)):\n",
    "            if expected_name.lower() in app_titles[i].lower():\n",
    "                best_match_url = app_urls[i]\n",
    "                break\n",
    "        \n",
    "        return best_match_url\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 앱 제목 가져오기\n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        # 앱 설명 가져오기\n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        # 앱 카테고리 가져오기\n",
    "        app_category_button = soup.find('a', {'itemprop': 'genre'})\n",
    "        app_category = app_category_button.text if app_category_button else 'Category not found'\n",
    "        \n",
    "        return {\n",
    "            'url': app_url,\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# 앱 이름과 예상된 정확한 제목 매핑 리스트\n",
    "app_names = {\n",
    "    \"카카오톡\": \"KakaoTalk\",\n",
    "    \"파파고\": \"Papago\",\n",
    "    \"카카오맵\": \"KakaoMap\",\n",
    "    \"네이버\": \"NAVER\",\n",
    "    \"쿠팡\": \"Coupang\"\n",
    "}\n",
    "\n",
    "# 각 앱의 URL 수집 및 정보 크롤링\n",
    "for app_name, expected_name in app_names.items():\n",
    "    app_url = get_best_match_app_url(app_name, expected_name)\n",
    "    if app_url:\n",
    "        app_info = get_app_info(app_url)\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No URL found for app: 카카오톡\n",
      "No URL found for app: 파파고\n",
      "No URL found for app: 카카오맵\n",
      "No URL found for app: 네이버\n",
      "No URL found for app: 쿠팡\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_best_match_app_url(search_query, expected_name, num_results=10):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response.encoding = 'utf-8'\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser', from_encoding='utf-8')\n",
    "        \n",
    "        app_urls = []\n",
    "        app_titles = []\n",
    "        app_descriptions = []\n",
    "        \n",
    "        for a in soup.find_all('a', {'class': 'Si6A0c Gy4nib'}, limit=num_results):\n",
    "            app_url = 'https://play.google.com' + a['href']\n",
    "            app_title_div = a.find('div', {'class': 'WsMG1c nnK0zc'})\n",
    "            if app_title_div:\n",
    "                app_title = app_title_div.text\n",
    "                app_urls.append(app_url)\n",
    "                app_titles.append(app_title)\n",
    "            \n",
    "            app_description_div = a.find('div', {'class': 'b8cIId ReQCgd Q9MA7b'})\n",
    "            if app_description_div:\n",
    "                app_description = app_description_div.text\n",
    "                app_descriptions.append(app_description)\n",
    "        \n",
    "        best_match_url = None\n",
    "        best_match_description = None\n",
    "        for i in range(len(app_titles)):\n",
    "            if expected_name.lower() in app_titles[i].lower():\n",
    "                best_match_url = app_urls[i]\n",
    "                best_match_description = app_descriptions[i] if i < len(app_descriptions) else 'Description not found'\n",
    "                break\n",
    "        \n",
    "        return best_match_url, best_match_description\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return None, None\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response.encoding = 'utf-8'\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser', from_encoding='utf-8')\n",
    "        \n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        app_category_button = soup.find('a', {'itemprop': 'genre'})\n",
    "        app_category = app_category_button.text if app_category_button else 'Category not found'\n",
    "        \n",
    "        return {\n",
    "            'url': app_url,\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "app_names = {\n",
    "    \"카카오톡\": \"KakaoTalk\",\n",
    "    \"파파고\": \"Papago\",\n",
    "    \"카카오맵\": \"KakaoMap\",\n",
    "    \"네이버\": \"NAVER\",\n",
    "    \"쿠팡\": \"Coupang\"\n",
    "}\n",
    "\n",
    "for app_name, expected_name in app_names.items():\n",
    "    app_url, app_description = get_best_match_app_url(app_name, expected_name)\n",
    "    if app_url:\n",
    "        app_info = get_app_info(app_url)\n",
    "        app_info['description'] = app_description  # 검색 결과에서 가져온 설명을 사용\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No URL found for app: 카카오톡\n",
      "No URL found for app: 파파고\n",
      "No URL found for app: 카카오맵\n",
      "No URL found for app: 네이버\n",
      "No URL found for app: 쿠팡\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_search_url(app_name):\n",
    "    base_url = \"https://play.google.com/store/search?q=\"\n",
    "    query = quote(app_name)\n",
    "    return f\"{base_url}{query}&c=apps\"\n",
    "\n",
    "def get_best_match_app_url(search_query, expected_name, num_results=10):\n",
    "    search_url = get_search_url(search_query)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response.encoding = 'utf-8'\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser', from_encoding='utf-8')\n",
    "        \n",
    "        app_urls = []\n",
    "        app_titles = []\n",
    "        app_descriptions = []\n",
    "        \n",
    "        for div in soup.find_all('div', {'class': 'Vpfmgd'}, limit=num_results):\n",
    "            a_tag = div.find('a', {'class': 'Qfxief'})\n",
    "            if a_tag:\n",
    "                app_url = 'https://play.google.com' + a_tag['href']\n",
    "                app_title_div = div.find('div', {'class': 'vWM94c'})\n",
    "                if app_title_div:\n",
    "                    app_title = app_title_div.text\n",
    "                    app_urls.append(app_url)\n",
    "                    app_titles.append(app_title)\n",
    "                \n",
    "                app_description_div = div.find('div', {'class': 'omXQ6c'})\n",
    "                if app_description_div:\n",
    "                    app_description = app_description_div.text\n",
    "                    app_descriptions.append(app_description)\n",
    "        \n",
    "        best_match_url = None\n",
    "        best_match_description = None\n",
    "        for i in range(len(app_titles)):\n",
    "            if expected_name.lower() in app_titles[i].lower():\n",
    "                best_match_url = app_urls[i]\n",
    "                best_match_description = app_descriptions[i] if i < len(app_descriptions) else 'Description not found'\n",
    "                break\n",
    "        \n",
    "        return best_match_url, best_match_description\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the search page. Status code: {response.status_code}\")\n",
    "        return None, None\n",
    "\n",
    "def get_app_info(app_url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(app_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response.encoding = 'utf-8'\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser', from_encoding='utf-8')\n",
    "        \n",
    "        app_title = soup.find('h1', {'class': 'Fd93Bb'}).text if soup.find('h1', {'class': 'Fd93Bb'}) else 'Title not found'\n",
    "        \n",
    "        app_description_meta = soup.find('meta', {'itemprop': 'description'})\n",
    "        app_description = app_description_meta['content'] if app_description_meta else 'Description not found'\n",
    "        \n",
    "        app_category_button = soup.find('a', {'itemprop': 'genre'})\n",
    "        app_category = app_category_button.text if app_category_button else 'Category not found'\n",
    "        \n",
    "        return {\n",
    "            'url': app_url,\n",
    "            'title': app_title,\n",
    "            'description': app_description,\n",
    "            'category': app_category\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the app page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# 앱 이름과 예상된 정확한 제목 매핑 리스트\n",
    "app_names = {\n",
    "    \"카카오톡\": \"KakaoTalk\",\n",
    "    \"파파고\": \"Papago\",\n",
    "    \"카카오맵\": \"KakaoMap\",\n",
    "    \"네이버\": \"NAVER\",\n",
    "    \"쿠팡\": \"Coupang\"\n",
    "}\n",
    "\n",
    "# 각 앱의 URL 수집 및 정보 크롤링\n",
    "for app_name, expected_name in app_names.items():\n",
    "    app_url, app_description = get_best_match_app_url(app_name, expected_name)\n",
    "    if app_url:\n",
    "        app_info = get_app_info(app_url)\n",
    "        app_info['description'] = app_description  # 검색 결과에서 가져온 설명을 사용\n",
    "        print(app_info)\n",
    "    else:\n",
    "        print(f\"No URL found for app: {app_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
